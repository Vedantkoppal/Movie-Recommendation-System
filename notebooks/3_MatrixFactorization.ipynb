{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-9tCUnK5-P3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lA4AEpE6jYK"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzWVyQlB8N-D"
      },
      "outputs": [],
      "source": [
        "movies = pd.read_csv('movies.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyzIK3YB6rCo"
      },
      "outputs": [],
      "source": [
        "# Prepare matrices\n",
        "user_ids = ratings[\"userId\"].unique()\n",
        "movie_ids = ratings[\"movieId\"].unique()\n",
        "n_users = len(user_ids)\n",
        "n_items = len(movie_ids)\n",
        "\n",
        "user_map = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
        "movie_map = {movie_id: idx for idx, movie_id in enumerate(movie_ids)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25_weBZn6r_w"
      },
      "outputs": [],
      "source": [
        "R = np.zeros((n_users, n_items))\n",
        "for _, row in ratings.iterrows():\n",
        "    user_idx = user_map[row[\"userId\"]]\n",
        "    movie_idx = movie_map[row[\"movieId\"]]\n",
        "    R[user_idx, movie_idx] = row[\"rating\"]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "R_tensor = torch.tensor(R, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET2DTGF06uaw",
        "outputId": "a0ca39fc-2df7-423e-cc78-d81f9682877c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5AUx1S-6wGQ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "n_factors = 10  # Number of latent factors\n",
        "alpha = 0.01    # Learning rate\n",
        "lambda_reg = 0.1  # Regularization strength\n",
        "n_epochs = 1000  # Number of epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiliN5IX60DP"
      },
      "outputs": [],
      "source": [
        "# Model Definition\n",
        "class MatrixFactorization(nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors):\n",
        "        super(MatrixFactorization, self).__init__()\n",
        "        self.user_factors = nn.Embedding(n_users, n_factors)  # User latent features\n",
        "        self.item_factors = nn.Embedding(n_items, n_factors)  # Item latent features\n",
        "\n",
        "    def forward(self, user_idx, item_idx):\n",
        "        user_latent = self.user_factors(user_idx)\n",
        "        item_latent = self.item_factors(item_idx)\n",
        "        return (user_latent * item_latent).sum(dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vzrM1TO64YG"
      },
      "outputs": [],
      "source": [
        "# Initialize model and move to GPU\n",
        "model = MatrixFactorization(n_users, n_items, n_factors).to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=alpha)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPk7EPFq67LR"
      },
      "outputs": [],
      "source": [
        "# Prepare data and move to GPU\n",
        "user_indices, item_indices = R.nonzero()\n",
        "ratings = torch.tensor(R[user_indices, item_indices], dtype=torch.float32).to(device)\n",
        "user_indices = torch.tensor(user_indices, dtype=torch.long).to(device)\n",
        "item_indices = torch.tensor(item_indices, dtype=torch.long).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlr7HUpi69Hm",
        "outputId": "af15f908-f7dd-451d-d156-82f9dc25bcea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 62.2244\n",
            "Epoch 50, Loss: 40.3733\n",
            "Epoch 100, Loss: 26.1636\n",
            "Epoch 150, Loss: 18.1215\n",
            "Epoch 200, Loss: 14.6853\n",
            "Epoch 250, Loss: 13.2494\n",
            "Epoch 300, Loss: 12.7762\n",
            "Epoch 350, Loss: 12.6170\n",
            "Epoch 400, Loss: 12.5483\n",
            "Epoch 450, Loss: 12.5117\n",
            "Epoch 500, Loss: 12.4898\n",
            "Epoch 550, Loss: 12.4757\n",
            "Epoch 600, Loss: 12.4664\n",
            "Epoch 650, Loss: 12.4599\n",
            "Epoch 700, Loss: 12.4553\n",
            "Epoch 750, Loss: 12.4520\n",
            "Epoch 800, Loss: 12.4495\n",
            "Epoch 850, Loss: 12.4477\n",
            "Epoch 900, Loss: 12.4463\n",
            "Epoch 950, Loss: 12.4452\n"
          ]
        }
      ],
      "source": [
        "# Training loop with GPU support\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Predict ratings and compute loss\n",
        "    predictions = model(user_indices, item_indices)\n",
        "    loss = loss_fn(predictions, ratings)\n",
        "\n",
        "    # Add regularization\n",
        "    reg_loss = lambda_reg * (model.user_factors.weight.norm(2) + model.item_factors.weight.norm(2))\n",
        "    total_loss = loss + reg_loss\n",
        "\n",
        "    # Backpropagation\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jc5hPKh6_ru"
      },
      "outputs": [],
      "source": [
        "# Extract latent features\n",
        "P = model.user_factors.weight.detach().cpu().numpy()  # User latent matrix\n",
        "Q = model.item_factors.weight.detach().cpu().numpy()  # Item latent matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzikQ5Im7W47"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "-fxsZR4n7tCr",
        "outputId": "81a50108-e8a6-4055-c435-fd9c51ee994e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;NearestNeighbors<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.NearestNeighbors.html\">?<span>Documentation for NearestNeighbors</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_jobs=-1, n_neighbors=20)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "NearestNeighbors(metric='cosine', n_jobs=-1, n_neighbors=20)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit KNN model on Q\n",
        "knn = NearestNeighbors(metric='cosine', algorithm='auto', n_neighbors=20, n_jobs=-1)\n",
        "knn.fit(Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XGQjA7p7v-T"
      },
      "outputs": [],
      "source": [
        "def recommend_movies(movieId, movie_map, movie_map_reverse, knn_model, Q):\n",
        "    \"\"\"\n",
        "    Recommend top 20 similar movies to the given movieId.\n",
        "\n",
        "    Args:\n",
        "        movieId (int): ID of the movie for which recommendations are needed.\n",
        "        movie_map (dict): Dictionary mapping movieId to row index in Q.\n",
        "        movie_map_reverse (dict): Dictionary mapping row index in Q to movieId.\n",
        "        knn_model: Trained KNN model.\n",
        "        Q (ndarray): Item latent feature matrix.\n",
        "\n",
        "    Returns:\n",
        "        list: List of (movieId, similarity score) tuples for top 20 similar movies.\n",
        "    \"\"\"\n",
        "    if movieId not in movie_map:\n",
        "        raise ValueError(f\"MovieId {movieId} is not in the dataset.\")\n",
        "\n",
        "    movie_idx = movie_map[movieId]\n",
        "    distances, indices = knn_model.kneighbors([Q[movie_idx]], n_neighbors=41)  # n_neighbors=21 to exclude the movie itself\n",
        "\n",
        "    recommendations = []\n",
        "    for dist, idx in zip(distances[0][1:], indices[0][1:]):  # Exclude the input movie itself\n",
        "        similar_movieId = movie_map_reverse[idx]\n",
        "        recommendations.append((similar_movieId, 1 - dist))  # 1 - dist converts cosine distance to similarity\n",
        "\n",
        "    return recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeMjh_DE7-Oe"
      },
      "outputs": [],
      "source": [
        "# Create reverse map for mapping indices back to movieId\n",
        "movie_map_reverse = {v: k for k, v in movie_map.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hkr-ZA5P8ATu"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "movie_id = 1  # Replace with a valid movieId from your dataset\n",
        "top_recommendations = recommend_movies(movie_id, movie_map, movie_map_reverse, knn, Q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apayUr0V8Ckm",
        "outputId": "cdc2bcf4-af38-4208-c94b-6b24ab183c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top recommendations for MovieId 1:\n",
            "MovieId: 165, Similarity: 1.0000\n",
            "MovieId: 454, Similarity: 1.0000\n",
            "MovieId: 527, Similarity: 1.0000\n",
            "MovieId: 434, Similarity: 0.9999\n",
            "MovieId: 161, Similarity: 0.9999\n",
            "MovieId: 349, Similarity: 0.9999\n",
            "MovieId: 588, Similarity: 0.9999\n",
            "MovieId: 736, Similarity: 0.9999\n",
            "MovieId: 500, Similarity: 0.9999\n",
            "MovieId: 2571, Similarity: 0.9999\n",
            "MovieId: 592, Similarity: 0.9998\n",
            "MovieId: 50, Similarity: 0.9998\n",
            "MovieId: 377, Similarity: 0.9998\n",
            "MovieId: 185, Similarity: 0.9998\n",
            "MovieId: 367, Similarity: 0.9998\n",
            "MovieId: 292, Similarity: 0.9997\n",
            "MovieId: 648, Similarity: 0.9997\n",
            "MovieId: 339, Similarity: 0.9997\n",
            "MovieId: 316, Similarity: 0.9997\n",
            "MovieId: 587, Similarity: 0.9997\n",
            "MovieId: 260, Similarity: 0.9997\n",
            "MovieId: 344, Similarity: 0.9997\n",
            "MovieId: 364, Similarity: 0.9997\n",
            "MovieId: 137, Similarity: 0.9996\n",
            "MovieId: 590, Similarity: 0.9996\n",
            "MovieId: 589, Similarity: 0.9996\n",
            "MovieId: 231, Similarity: 0.9996\n",
            "MovieId: 32, Similarity: 0.9995\n",
            "MovieId: 595, Similarity: 0.9994\n",
            "MovieId: 95, Similarity: 0.9994\n",
            "MovieId: 780, Similarity: 0.9994\n",
            "MovieId: 160, Similarity: 0.9993\n",
            "MovieId: 457, Similarity: 0.9992\n",
            "MovieId: 225, Similarity: 0.9991\n",
            "MovieId: 380, Similarity: 0.9991\n",
            "MovieId: 539, Similarity: 0.9990\n",
            "MovieId: 296, Similarity: 0.9990\n",
            "MovieId: 208, Similarity: 0.9990\n",
            "MovieId: 329, Similarity: 0.9988\n",
            "MovieId: 597, Similarity: 0.9985\n"
          ]
        }
      ],
      "source": [
        "print(f\"Top recommendations for MovieId {movie_id}:\")\n",
        "for rec_movie_id, score in top_recommendations:\n",
        "    print(f\"MovieId: {rec_movie_id}, Similarity: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgETKqhP8E4t"
      },
      "outputs": [],
      "source": [
        "def print_movie_recommendations(top_recommendations, movies):\n",
        "    \"\"\"\n",
        "    Print the top movie recommendations with similarity scores.\n",
        "\n",
        "    Args:\n",
        "        top_recommendations (list of tuples): List containing tuples of (movieId, similarity_score)\n",
        "        movies (DataFrame): DataFrame containing movieId and title\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(f\"Top recommendations:\")\n",
        "    for rec_movie_id, score in top_recommendations:\n",
        "        # Get the movie title from the movieId\n",
        "        movie_title = movies[movies['movieId'] == rec_movie_id]['title'].values[0]\n",
        "        print(f\"{movie_title}, Similarity: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNhvn0QK8q6R"
      },
      "outputs": [],
      "source": [
        "def get_movie_id_from_title(title, movies):\n",
        "    movie_id = movies[movies['title'] == title]['movieId'].values\n",
        "    if len(movie_id) > 0:\n",
        "        return movie_id[0]\n",
        "    else:\n",
        "        return None  # Return None if movie title not found\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-D95B-58sKY"
      },
      "outputs": [],
      "source": [
        "title = \"Mad Max: Fury Road (2015)\"  # Replace with a movie title\n",
        "movie_id = get_movie_id_from_title(title, movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsJmCnLxBjjL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9rWCIjy85vX"
      },
      "outputs": [],
      "source": [
        "top_recommendations = recommend_movies(movie_id, movie_map, movie_map_reverse, knn, Q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eUHvkuK9uwt",
        "outputId": "ef110efb-f1d5-45ab-9be8-0aa453c1c395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top recommendations:\n",
            "Selfish Giant, The (2013), Similarity: 1.0000\n",
            "The Dark Tower (2017), Similarity: 1.0000\n",
            "Mamma Mia: Here We Go Again! (2018), Similarity: 1.0000\n",
            "Logan Lucky (2017), Similarity: 1.0000\n",
            "Race to Witch Mountain (2009), Similarity: 1.0000\n",
            "The Secret Life of Pets (2016), Similarity: 1.0000\n",
            "The Mummy (2017), Similarity: 1.0000\n",
            "Black Mirror, Similarity: 1.0000\n",
            "Way Back, The (2010), Similarity: 1.0000\n",
            "Game Night (2018), Similarity: 1.0000\n",
            "Moana (2016), Similarity: 1.0000\n",
            "Life of Pi (2012), Similarity: 1.0000\n",
            "The Revenant (2015), Similarity: 1.0000\n",
            "Oblivion (2013), Similarity: 1.0000\n",
            "What If (2013), Similarity: 1.0000\n",
            "The Hunger Games: Mockingjay - Part 1 (2014), Similarity: 1.0000\n",
            "Beauty and the Beast (2017), Similarity: 1.0000\n",
            "Black Mirror: White Christmas (2014), Similarity: 1.0000\n",
            "Journey to the West: Conquering the Demons (Daai wa sai you chi Chui mo chun kei) (2013), Similarity: 1.0000\n",
            "Alpha (2018), Similarity: 1.0000\n",
            "Librarian: Quest for the Spear, The (2004), Similarity: 1.0000\n",
            "Little Shop of Horrors (1986), Similarity: 1.0000\n",
            "Fireworks, Should We See It from the Side or the Bottom? (2017), Similarity: 1.0000\n",
            "Asterix & Obelix: Mission Cleopatra (Astérix & Obélix: Mission Cléopâtre) (2002), Similarity: 1.0000\n",
            "Victoria (2015), Similarity: 1.0000\n",
            "Coraline (2009), Similarity: 1.0000\n",
            "Kizumonogatari II: Passionate Blood (2016), Similarity: 1.0000\n",
            "Fullmetal Alchemist 2018 (2017), Similarity: 1.0000\n",
            "Blue Exorcist: The Movie (2012), Similarity: 1.0000\n",
            "Unedited Footage of a Bear (2014), Similarity: 1.0000\n",
            "The Clapper (2018), Similarity: 1.0000\n",
            "The Thinning (2016), Similarity: 1.0000\n",
            "Sword Art Online The Movie: Ordinal Scale (2017), Similarity: 1.0000\n",
            "Gintama (2017), Similarity: 1.0000\n",
            "Too Funny to Fail: The Life and Death of The Dana Carvey Show (2017), Similarity: 1.0000\n",
            "Kizumonogatari III: Cold Blood (2017), Similarity: 1.0000\n",
            "Love Live! The School Idol Movie (2015), Similarity: 1.0000\n",
            "Tickling Giants (2017), Similarity: 1.0000\n",
            "Gintama: The Final Chapter - Be Forever Yorozuya (2013), Similarity: 1.0000\n",
            "Betting on Zero (2016), Similarity: 1.0000\n"
          ]
        }
      ],
      "source": [
        "print_movie_recommendations(top_recommendations=top_recommendations,movies=movies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhDBVitG-Kuh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# List of variables to save\n",
        "variables_to_save = {\n",
        "    'P': P,\n",
        "    'Q': Q,\n",
        "    'movie_map_reverse': movie_map_reverse,\n",
        "    'user_map': user_map,\n",
        "    'knn_model': knn,\n",
        "    'movie_ids': movie_ids,\n",
        "    'user_ids': user_ids\n",
        "}\n",
        "\n",
        "# Save the variables to a file\n",
        "with open('/content/model_variables.pkl', 'wb') as f:\n",
        "    pickle.dump(variables_to_save, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGQFrTSwCdRE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rHgyqd3D1sI"
      },
      "source": [
        "# using gidserach cv for best prams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFtV-2MfD6BI",
        "outputId": "8158a1f4-dde1-4ae0-dc50-1de383c91773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 4.865091800689697\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 4.799771785736084\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 4.759719371795654\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 4.694297790527344\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 4.60194206237793\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 4.681056499481201\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 4.504985809326172\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 4.38636589050293\n",
            "Training with n_factors=10, alpha=0.001, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 4.249305725097656\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 4.594008445739746\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 4.5468926429748535\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 4.4354963302612305\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 4.380541801452637\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 4.087109565734863\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.9694128036499023\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.8075358867645264\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.6942858695983887\n",
            "Training with n_factors=10, alpha=0.01, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.664673089981079\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 4.111115455627441\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 3.900454521179199\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 3.8088624477386475\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 3.694106340408325\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 3.647987127304077\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.648383617401123\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.6498560905456543\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.6495273113250732\n",
            "Training with n_factors=10, alpha=0.1, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.6491122245788574\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 5.756364822387695\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 5.749237537384033\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 5.691935062408447\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 5.6536383628845215\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 5.528669834136963\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 5.542357444763184\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 5.456257343292236\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 5.169543266296387\n",
            "Training with n_factors=20, alpha=0.001, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 4.911840438842773\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 5.553095817565918\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 5.3043012619018555\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 5.165280818939209\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 5.09236478805542\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 4.701194763183594\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 4.402419567108154\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 4.218695640563965\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.845278739929199\n",
            "Training with n_factors=20, alpha=0.01, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.7255666255950928\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 4.568469524383545\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 4.178471565246582\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 3.9951422214508057\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 3.8170056343078613\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 3.671360731124878\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.6507325172424316\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.6506993770599365\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.6496548652648926\n",
            "Training with n_factors=20, alpha=0.1, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.6504902839660645\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 6.639512062072754\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 6.541115760803223\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 6.409054756164551\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 6.562182426452637\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 6.406905174255371\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 6.228862285614014\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 6.227077484130859\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 5.959604263305664\n",
            "Training with n_factors=30, alpha=0.001, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 5.620789051055908\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 6.29644250869751\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 5.993710517883301\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 5.753803730010986\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 5.742119789123535\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 5.270907878875732\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 4.916904449462891\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 4.643985748291016\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 4.067645072937012\n",
            "Training with n_factors=30, alpha=0.01, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.8563625812530518\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 4.969121932983398\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 4.508443355560303\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 4.228395938873291\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 3.9821059703826904\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 3.7141053676605225\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.663892984390259\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.6519124507904053\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.6499032974243164\n",
            "Training with n_factors=30, alpha=0.1, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.649735450744629\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 7.251558780670166\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 7.354732036590576\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 7.213681697845459\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 7.223417282104492\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 7.151174068450928\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 7.006949424743652\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 6.887067794799805\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 6.6214141845703125\n",
            "Training with n_factors=40, alpha=0.001, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 6.25278377532959\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 6.852325439453125\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 6.608257293701172\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 6.3233771324157715\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 6.423666000366211\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 5.81483268737793\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 5.4549031257629395\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 5.074223041534424\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 4.337377071380615\n",
            "Training with n_factors=40, alpha=0.01, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.983644962310791\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 5.466439247131348\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 4.799599647521973\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 4.448402404785156\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 4.18358850479126\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 3.783263683319092\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.680647134780884\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.6500654220581055\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.6505556106567383\n",
            "Training with n_factors=40, alpha=0.1, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.650010585784912\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 7.8674540519714355\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 7.958146572113037\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 7.757312297821045\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 7.918211936950684\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 7.777172088623047\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 7.632576942443848\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 7.577824592590332\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 7.147509574890137\n",
            "Training with n_factors=50, alpha=0.001, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 6.937387466430664\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 7.49025297164917\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 7.216196060180664\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 6.983634948730469\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 6.989592552185059\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 6.29824686050415\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 5.90119743347168\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 5.532320976257324\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 4.607224464416504\n",
            "Training with n_factors=50, alpha=0.01, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 4.158252716064453\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.01, n_epochs=500\n",
            "RMSE: 5.777002811431885\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.01, n_epochs=1000\n",
            "RMSE: 5.0825018882751465\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.01, n_epochs=1500\n",
            "RMSE: 4.77594518661499\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.1, n_epochs=500\n",
            "RMSE: 4.436577320098877\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.1, n_epochs=1000\n",
            "RMSE: 3.867340326309204\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.1, n_epochs=1500\n",
            "RMSE: 3.7209668159484863\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.5, n_epochs=500\n",
            "RMSE: 3.6524927616119385\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.5, n_epochs=1000\n",
            "RMSE: 3.652538537979126\n",
            "Training with n_factors=50, alpha=0.1, lambda_reg=0.5, n_epochs=1500\n",
            "RMSE: 3.6497795581817627\n",
            "Best Parameters: {'n_factors': 10, 'alpha': 0.1, 'lambda_reg': 0.1, 'n_epochs': 1000}\n",
            "Best RMSE: 3.647987127304077\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the Matrix Factorization Model\n",
        "class MatrixFactorization(nn.Module):\n",
        "    def __init__(self, num_users, num_movies, n_factors):\n",
        "        super(MatrixFactorization, self).__init__()\n",
        "        # User and movie embeddings\n",
        "        self.user_factors = nn.Embedding(num_users, n_factors)\n",
        "        self.movie_factors = nn.Embedding(num_movies, n_factors)\n",
        "\n",
        "    def forward(self, user, movie):\n",
        "        # Compute the dot product of user and movie latent vectors\n",
        "        return (self.user_factors(user) * self.movie_factors(movie)).sum(1)\n",
        "\n",
        "# Helper function to train and evaluate MF with PyTorch\n",
        "def train_and_evaluate_mf(model, train_data, test_data, alpha, lambda_reg, n_epochs):\n",
        "    # Loss function (mean squared error)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # Optimizer (Stochastic Gradient Descent)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=alpha)\n",
        "\n",
        "    # Move data to device (GPU or CPU)\n",
        "    train_data = train_data.to(device)\n",
        "    test_data = test_data.to(device)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the users, movies, and ratings from training data\n",
        "        users = train_data[:, 0].long()  # Ensure it's Long tensor\n",
        "        movies = train_data[:, 1].long()  # Ensure it's Long tensor\n",
        "        ratings = train_data[:, 2].float()\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model(users, movies)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(predictions, ratings)\n",
        "\n",
        "        # Add regularization term\n",
        "        loss += lambda_reg * (model.user_factors(users).norm(2).sum() + model.movie_factors(movies).norm(2).sum())\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        users = test_data[:, 0].long()  # Ensure it's Long tensor\n",
        "        movies = test_data[:, 1].long()  # Ensure it's Long tensor\n",
        "        true_ratings = test_data[:, 2].float()\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model(users, movies)\n",
        "\n",
        "        # Compute RMSE (use torch.sqrt and torch.mean)\n",
        "        mse = torch.mean((predictions - true_ratings) ** 2)\n",
        "        rmse = torch.sqrt(mse)\n",
        "\n",
        "    return rmse.item()  # Convert tensor to Python float for easy display\n",
        "\n",
        "# Grid Search Loop\n",
        "def grid_search(ratings, n_factors_options, alpha_options, lambda_reg_options, n_epochs_options):\n",
        "    # Prepare the dataset\n",
        "    user_ids = ratings['userId'].unique()\n",
        "    movie_ids = ratings['movieId'].unique()\n",
        "\n",
        "    # Map user and movie ids to indices\n",
        "    user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
        "    movie_to_idx = {movie: idx for idx, movie in enumerate(movie_ids)}\n",
        "\n",
        "    # Encode userId and movieId as indices\n",
        "    ratings['userId'] = ratings['userId'].map(user_to_idx)\n",
        "    ratings['movieId'] = ratings['movieId'].map(movie_to_idx)\n",
        "\n",
        "    # Train-test split\n",
        "    train_data, test_data = train_test_split(ratings, test_size=0.2)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_tensor = torch.tensor(train_data[['userId', 'movieId', 'rating']].values)\n",
        "    test_tensor = torch.tensor(test_data[['userId', 'movieId', 'rating']].values)\n",
        "\n",
        "    # Initialize variables to track best parameters\n",
        "    best_rmse = float('inf')\n",
        "    best_params = None\n",
        "\n",
        "    # Grid search over hyperparameters\n",
        "    for n_factors in n_factors_options:\n",
        "        for alpha in alpha_options:\n",
        "            for lambda_reg in lambda_reg_options:\n",
        "                for n_epochs in n_epochs_options:\n",
        "                    print(f\"Training with n_factors={n_factors}, alpha={alpha}, lambda_reg={lambda_reg}, n_epochs={n_epochs}\")\n",
        "\n",
        "                    # Initialize model\n",
        "                    model = MatrixFactorization(len(user_ids), len(movie_ids), n_factors).to(device)\n",
        "\n",
        "                    # Train and evaluate the model\n",
        "                    rmse = train_and_evaluate_mf(model, train_tensor, test_tensor, alpha, lambda_reg, n_epochs)\n",
        "                    print(f\"RMSE: {rmse}\")\n",
        "\n",
        "                    # Update the best model if current is better\n",
        "                    if rmse < best_rmse:\n",
        "                        best_rmse = rmse\n",
        "                        best_params = {\n",
        "                            'n_factors': n_factors,\n",
        "                            'alpha': alpha,\n",
        "                            'lambda_reg': lambda_reg,\n",
        "                            'n_epochs': n_epochs\n",
        "                        }\n",
        "\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best RMSE: {best_rmse}\")\n",
        "\n",
        "# Define the grid of hyperparameters to search\n",
        "n_factors_options = [10, 20, 30, 40, 50]\n",
        "alpha_options = [0.001, 0.01, 0.1]\n",
        "lambda_reg_options = [0.01, 0.1, 0.5]\n",
        "n_epochs_options = [500, 1000, 1500]\n",
        "\n",
        "# Load your dataset (ensure it contains userId, movieId, and rating)\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search(ratings, n_factors_options, alpha_options, lambda_reg_options, n_epochs_options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsnT3WUfD92Q"
      },
      "outputs": [],
      "source": [
        "def get_best_P_and_Q(ratings, best_params):\n",
        "    # Extract best hyperparameters\n",
        "    n_factors = best_params['n_factors']\n",
        "    alpha = best_params['alpha']\n",
        "    lambda_reg = best_params['lambda_reg']\n",
        "    n_epochs = best_params['n_epochs']\n",
        "\n",
        "    # Prepare the dataset\n",
        "    user_ids = ratings['userId'].unique()\n",
        "    movie_ids = ratings['movieId'].unique()\n",
        "\n",
        "    # Map user and movie ids to indices\n",
        "    user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
        "    movie_to_idx = {movie: idx for idx, movie in enumerate(movie_ids)}\n",
        "\n",
        "    # Encode userId and movieId as indices\n",
        "    ratings['userId'] = ratings['userId'].map(user_to_idx)\n",
        "    ratings['movieId'] = ratings['movieId'].map(movie_to_idx)\n",
        "\n",
        "    # Train-test split\n",
        "    train_data, test_data = train_test_split(ratings, test_size=0.2)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    train_tensor = torch.tensor(train_data[['userId', 'movieId', 'rating']].values).to(device)\n",
        "    test_tensor = torch.tensor(test_data[['userId', 'movieId', 'rating']].values).to(device)\n",
        "\n",
        "    # Initialize the final model with the best hyperparameters\n",
        "    model = MatrixFactorization(len(user_ids), len(movie_ids), n_factors).to(device)\n",
        "\n",
        "    # Train the model with the best configuration\n",
        "    _ = train_and_evaluate_mf(model, train_tensor, test_tensor, alpha, lambda_reg, n_epochs)\n",
        "\n",
        "    # Get the P (user factors) and Q (movie factors) matrices from the trained model\n",
        "    P = model.user_factors.weight.data.cpu().numpy()  # User latent factors (P)\n",
        "    Q = model.movie_factors.weight.data.cpu().numpy()  # Movie latent factors (Q)\n",
        "\n",
        "    return P, Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR42ErQIGdLQ"
      },
      "outputs": [],
      "source": [
        "best_params = {\n",
        "    'n_factors': 10,  # Example best n_factors\n",
        "    'alpha': 0.1,    # Example best alpha\n",
        "    'lambda_reg': 0.1,  # Example best lambda_reg\n",
        "    'n_epochs': 1000  # Example best n_epochs\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaNsHsCxGVjl",
        "outputId": "5fd5b15d-494b-45a6-c1fd-6d87cb5a33b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best P (user latent factors):\n",
            "[[ 1.8544238e-03  3.1837909e-03 -1.2574281e-03 ... -1.3407281e-03\n",
            "  -2.3312890e-03 -5.8891056e-03]\n",
            " [ 1.5185139e-01  2.2354884e-01 -1.8456373e-01 ...  1.5082285e-01\n",
            "   2.2259624e-01 -3.6205858e-02]\n",
            " [-5.0297003e-02  2.6915249e-01  1.5612359e-01 ...  7.0591420e-02\n",
            "   1.9314998e-01 -1.0909347e-01]\n",
            " ...\n",
            " [ 9.9010405e-04  5.2981277e-04  2.0923044e-05 ... -8.5170445e-04\n",
            "  -2.6103796e-04  2.3769599e-04]\n",
            " [ 8.5837342e-02 -3.2578591e-01 -1.9702701e-01 ...  4.2254277e-02\n",
            "  -1.1068599e-01  6.0609568e-02]\n",
            " [ 1.5573979e-03  6.5696886e-04 -4.4141873e-04 ... -1.3986811e-04\n",
            "   2.4958437e-03 -4.4661996e-04]]\n",
            "Best Q (movie latent factors):\n",
            "[[ 0.10072616 -0.07361765 -0.13247243 ... -0.02049093  0.22202346\n",
            "   0.05959699]\n",
            " [ 0.36889273  0.55173945  0.9688095  ... -0.3188613  -0.15857975\n",
            "  -0.43352142]\n",
            " [-0.46798006  0.06764051  0.43066737 ...  0.34535494  0.3340185\n",
            "   0.02511735]\n",
            " ...\n",
            " [ 0.03553941  0.18098116 -0.6669928  ...  1.8792015   0.5931966\n",
            "  -0.25338715]\n",
            " [-0.75304127 -1.5435445   0.88999116 ... -2.1402876  -0.11773718\n",
            "   2.237833  ]\n",
            " [ 2.274988   -1.0533618  -0.14126618 ...  1.1657457  -0.22719567\n",
            "  -1.0675172 ]]\n"
          ]
        }
      ],
      "source": [
        "# Get the best P and Q matrices\n",
        "P, Q = get_best_P_and_Q(ratings, best_params)\n",
        "\n",
        "# Now you can use P and Q for recommendations or other tasks\n",
        "print(\"Best P (user latent factors):\")\n",
        "print(P)\n",
        "\n",
        "print(\"Best Q (movie latent factors):\")\n",
        "print(Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG-uE52mGYQ8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to precompute movie similarities based on Q matrix\n",
        "def precompute_movie_similarities(Q):\n",
        "    \"\"\"\n",
        "    Precompute the cosine similarity between all movies using their latent vectors.\n",
        "    Args:\n",
        "    - Q (np.ndarray): The movie latent factors matrix of shape (num_movies, n_factors).\n",
        "\n",
        "    Returns:\n",
        "    - similarity_matrix (np.ndarray): Cosine similarity matrix of shape (num_movies, num_movies).\n",
        "    \"\"\"\n",
        "    # Compute the cosine similarity between all pairs of movie latent vectors (rows of Q)\n",
        "    similarity_matrix = cosine_similarity(Q)\n",
        "\n",
        "    return similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bh2YFL-HjLX"
      },
      "outputs": [],
      "source": [
        "similarity_matrix = precompute_movie_similarities(Q)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "GMDz-SBWINRX",
        "outputId": "bfd3b999-e205-4043-e9af-dc262b53317d"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'122904'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-26d4f713322d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovie_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_map_reverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'122904'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '122904'"
          ]
        }
      ],
      "source": [
        "movie_index = movie_map_reverse['122904']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-mc9R25H2In",
        "outputId": "40e5a23c-99da-4a46-f2e4-cc8d48f02a69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.3797824 ,  0.99999994,  0.30541682, ..., -0.26379767,\n",
              "       -0.07518862,  0.19542608], dtype=float32)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarities = similarity_matrix[1]\n",
        "similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdkI_pxJIjDu",
        "outputId": "637b597b-0803-4604-8e44-6d485a3ca004"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   1, 6644, 3747, ..., 9310, 8052, 4739])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_similarities = np.argsort(similarities)[::-1]\n",
        "sorted_similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-4bM4-BJYjc",
        "outputId": "569ce2f1-7748-42ae-b9b1-0b8fd98b6062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top recommendations for movie 'Toy Story (1995)':\n",
            "Movie: Ask the Dust (2006), Similarity: 0.9025\n",
            "Movie: Hollywood Chainsaw Hookers (1988), Similarity: 0.8929\n",
            "Movie: Harrison Bergeron (1995), Similarity: 0.8677\n",
            "Movie: 47 Ronin (2013), Similarity: 0.8456\n",
            "Movie: Yankee Doodle Dandy (1942), Similarity: 0.8415\n",
            "Movie: AVP: Alien vs. Predator (2004), Similarity: 0.8346\n",
            "Movie: Secret of NIMH, The (1982), Similarity: 0.8285\n",
            "Movie: Prometheus (2012), Similarity: 0.8265\n",
            "Movie: Last Supper, The (1995), Similarity: 0.8236\n",
            "Movie: Pawn (2013), Similarity: 0.8215\n",
            "Movie: Short Circuit 2 (1988), Similarity: 0.8143\n",
            "Movie: Simple Wish, A (1997), Similarity: 0.8124\n",
            "Movie: Tremors II: Aftershocks (1996), Similarity: 0.8105\n",
            "Movie: Now You See Me 2 (2016), Similarity: 0.8103\n",
            "Movie: Giant Spider Invasion, The (1975), Similarity: 0.8092\n",
            "Movie: Little Princess, A (1995), Similarity: 0.8072\n",
            "Movie: Bachelor, The (1999), Similarity: 0.8064\n",
            "Movie: In China They Eat Dogs (I Kina spiser de hunde) (1999), Similarity: 0.8036\n",
            "Movie: True Stories (1986), Similarity: 0.8006\n",
            "Movie: Reckless Kelly (1994), Similarity: 0.8002\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Assuming you've already trained your model and have best P and Q matrices\n",
        "# P: User factors matrix (num_users, n_factors)\n",
        "# Q: Movie factors matrix (num_movies, n_factors)\n",
        "\n",
        "# Example of how you might load or have these matrices\n",
        "# For example, loading P and Q from saved files if needed\n",
        "# P = np.load('P.npy')   # User factors matrix\n",
        "# Q = np.load('Q.npy')   # Movie factors matrix\n",
        "\n",
        "# Here, we assume P and Q are already available\n",
        "# Example: If you've trained them using PyTorch or another framework\n",
        "\n",
        "# Precompute the movie similarity matrix based on the latent factor matrix Q\n",
        "def precompute_movie_similarities(Q):\n",
        "    \"\"\"\n",
        "    Precompute the cosine similarity between all movies using their latent vectors in Q.\n",
        "    Args:\n",
        "    - Q (np.ndarray): The movie latent factors matrix of shape (num_movies, n_factors).\n",
        "\n",
        "    Returns:\n",
        "    - similarity_matrix (np.ndarray): Cosine similarity matrix of shape (num_movies, num_movies).\n",
        "    \"\"\"\n",
        "    similarity_matrix = cosine_similarity(Q)\n",
        "    return similarity_matrix\n",
        "\n",
        "# Function to get the movie ID from its title\n",
        "def get_movie_id_from_title(title, movies_df):\n",
        "    movie_id = movies_df[movies_df['title'] == title]['movieId'].values\n",
        "    if len(movie_id) == 0:\n",
        "        print(f\"Movie title '{title}' not found in dataset.\")\n",
        "        return None\n",
        "    return movie_id[0]\n",
        "\n",
        "# Function to get top N recommendations based on movie similarity\n",
        "def get_top_n_recommendations(movie_title, similarity_matrix, movie_map_reverse, top_n=20, movies_df=None):\n",
        "    \"\"\"\n",
        "    Get the top N movie recommendations for a given movie title based on the precomputed similarity matrix.\n",
        "    Args:\n",
        "    - movie_title (str): The title of the movie for which recommendations are needed.\n",
        "    - similarity_matrix (np.ndarray): The precomputed cosine similarity matrix.\n",
        "    - movie_map_reverse (dict): Reverse mapping from movie index to movieId.\n",
        "    - top_n (int): The number of recommendations to return.\n",
        "    - movies_df (pd.DataFrame): DataFrame containing movie details, including movieId and title.\n",
        "\n",
        "    Returns:\n",
        "    - List of tuples: [(recommended_movie_id, similarity_score), ...]\n",
        "    \"\"\"\n",
        "    movie_id = get_movie_id_from_title(movie_title, movies_df)\n",
        "    if movie_id is None:\n",
        "        return []\n",
        "\n",
        "    # Ensure the movie_id is valid in the mapping\n",
        "    if movie_id not in movie_map_reverse:\n",
        "        print(f\"Movie ID {movie_id} not found in movie_map_reverse.\")\n",
        "        return []\n",
        "\n",
        "    # Get the index of the movie in the matrix\n",
        "    movie_index = movie_map_reverse[movie_id]\n",
        "\n",
        "    # Get the similarity scores for the given movie\n",
        "    similarities = similarity_matrix[movie_index]\n",
        "\n",
        "    # Sort the movies by similarity (descending order) and get the top N recommendations\n",
        "    sorted_similarities = np.argsort(similarities)[::-1]\n",
        "\n",
        "    # Exclude the movie itself from recommendations\n",
        "    top_recommendations = []\n",
        "    count = 0\n",
        "    for idx in sorted_similarities:\n",
        "        if idx != movie_index:  # Exclude the movie itself\n",
        "            recommended_movie_id = movie_map_reverse[idx]\n",
        "            similarity_score = similarities[idx]\n",
        "            top_recommendations.append((recommended_movie_id, similarity_score))\n",
        "            count += 1\n",
        "        if count == top_n:\n",
        "            break\n",
        "\n",
        "    return top_recommendations\n",
        "\n",
        "# Load your movies DataFrame (movies.csv) to map movie titles and ids\n",
        "# movies = pd.read_csv('movies.csv')  # Make sure to have the movies.csv file\n",
        "\n",
        "# Reverse movie mapping from movieId to index in Q (assuming Q corresponds to movieId order)\n",
        "# movie_map_reverse = {idx: movie_id for idx, movie_id in enumerate(movies['movieId'].values)}\n",
        "\n",
        "# Precompute the similarity matrix between all movies\n",
        "similarity_matrix = precompute_movie_similarities(Q)\n",
        "\n",
        "# Example usage: Get top 20 recommendations for a given movie title\n",
        "movie_title = \"Toy Story (1995)\"  # Example movie title\n",
        "top_recommendations = get_top_n_recommendations(movie_title, similarity_matrix, movie_map_reverse, top_n=20, movies_df=movies_df)\n",
        "\n",
        "# Print top recommendations\n",
        "print(f\"Top recommendations for movie '{movie_title}':\")\n",
        "for rec_movie_id, score in top_recommendations:\n",
        "    # Fetch movie title from movie_id\n",
        "    rec_movie_title = movies_df[movies_df['movieId'] == rec_movie_id]['title'].values[0]\n",
        "    print(f\"Movie: {rec_movie_title}, Similarity: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "frO3frqjKnH8",
        "outputId": "d4a737a9-9eaf-4b0f-90a9-6897c2f1969d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables saved to 'saved_variables.pkl'\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}